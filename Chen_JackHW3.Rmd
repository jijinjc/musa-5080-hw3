---
title: "Geospatial Risk Prediction"
author: "Jack Chen"
date: "2024-10-12"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

# Introduction

The focus of this analysis will be on traffic crashes in Chicago, as travel is a very frequent action that people takes in their day to day life, and Chicago is a city that has very vehicle-oriented travel methods. Traffic crashes are influenced by a variety of factors, such as weather conditions, road infrastructure, and driver behavior. By studying the traffic crash in the city as well as highlight the potential risk factors that may have an affect on the traffic crash numbers, it is possible prevent or mitigate the risk of these incidents. However, bias could arise particularly when crashes are reported more frequently in areas with better surveillance or where residents are more likely to report incidents. For example, burglaries in Chicago is one of the most commonly recorded crime in open data, and there can be potential bias related to abandoned cars. This bias could have skewed crime data in specific neighborhoods, thus resulting in a large amount of recorded burglary cases. For traffic crashes, the issue of bias may be more significant, as there could be over-reporting around biases such as poor road conditions or drunk driving, leading to an inaccurate understanding of traffic safety across the city entirety of the city.

To do this, we will be looking at data from the [Chicago Data Portal](https://data.cityofchicago.org/), by collecting 2018 data for [traffic crashes](https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if/about_data), [bar locations](https://data.cityofchicago.org/Community-Economic-Development/bars/x7bm-cj66/about_data), as well as poor road conditions such as [broken street lights](https://data.cityofchicago.org/Service-Requests/311-Service-Requests-Street-Lights-All-Out-Histori/zuxi-7xem/about_data) and [pot holes](https://data.cityofchicago.org/Service-Requests/311-Service-Requests-Pot-Holes-Reported-Historical/7as2-ds3y/about_data). We will also be collecting 2019 data for traffic crashes to use near the end of the analysis to compare with the model that we will be creating to help with our predictions.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)

library(tidyverse)
library(sf)
library(RSocrata)
library(viridis)
library(spatstat.explore)
library(raster)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
library(classInt)
library(ggtext)
library(reshape2)
library(glue)
# functions
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
```

# Data Wrangling

## Police Data

We will first be downloading the data for Chicago's boundary, police districts and police beats. This different types of police administrative areas help us look at the analysis of traffic crashes at different granularities.

```{r police data, message=FALSE, warning=FALSE, results='hide'}
policeDistricts = 
  st_read("https://data.cityofchicago.org/api/geospatial/fthy-xz3r?method=export&format=GeoJSON") %>%
  st_transform('ESRI:102271') %>%
  dplyr::select(District = dist_num)
  
policeBeats = 
  st_read("https://data.cityofchicago.org/api/geospatial/aerh-rz74?method=export&format=GeoJSON") %>%
  st_transform('ESRI:102271') %>%
  dplyr::select(District = beat_num) 
  

bothPoliceUnits = rbind(mutate(policeDistricts, Legend = "Police Districts"), 
                         mutate(policeBeats, Legend = "Police Beats"))

chicagoBoundary = 
  st_read(file.path(root.dir,"/Chapter5/chicagoBoundary.geojson")) %>%
  st_transform('ESRI:102271') 
```

## Traffic Crash Data 2018

We then will be downloading our main incident of analysis: traffic crashes. The data here has already been filtered using Chicago Data Portal's query data function, therefore we will not need to manually filter the data in R one more time, as the data is already filtered to only be for 2018. To make the data easier to view while working in the analysis, we will only be keeping the important data such as the id, date, latitude, longitude, and location.

```{r crash data 2018, warning=FALSE, message=FALSE, results='hide'}
crash18 = read.csv("https://raw.githubusercontent.com/jijinjc/musa-5080-hw3/refs/heads/main/Assignment%20Data%20Files/Traffic_Crashes_-_2018.csv") %>%
    dplyr::select(CRASH_RECORD_ID, CRASH_DATE, LATITUDE, LONGITUDE, LOCATION) %>%
    na.omit() %>%
    st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs = 4326, agr = "constant")%>%
    st_transform('ESRI:102271') %>%
    distinct()
```

## Traffic Crash Visualization

With the crash data, we will do an initial visualization of the data to see exactly where the traffic crashes occur, as well as a density map of these crashes. The plot of traffic crashes shows that there are a lot of crash incidents in Chicago during 2018, but we can see more clearly that the density of these crashes happen near the loop within Chicago.

```{r visualization of crashes, warning=FALSE, message=FALSE}
grid.arrange(ncol=2,
ggplot() + 
  geom_sf(data = chicagoBoundary) +
  geom_sf(data = crash18, colour="red", size=0.1, show.legend = "point", alpha = 0.5) +
  labs(title= "Traffic Crashes, Chicago - 2018") +
  mapTheme(title_size = 14),

ggplot() + 
  geom_sf(data = chicagoBoundary, fill = "grey40") +
  stat_density2d(data = data.frame(st_coordinates(crash18)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 70, geom = 'polygon') +
  scale_fill_viridis() +
  scale_alpha(range = c(0.00, 0.5), guide = FALSE) +
  labs(title = "Density of Traffic Crashes in Chicago") +
  mapTheme(title_size = 14) + theme(legend.position = "none"))
```

## Fishnet Generation and Visualization

Following the visualization of the location and density of the traffic crash locations, we can proceed to create our fishnet. The fishnet will be useed to represent spatial trend of traffic crash in a regression-ready form, and we will use the fishnet to visualize the traffic crash incidents for each grid cell. Again in this fishnet visualization, we see that Chicago's Loop sees the highest number of traffic crash incidents.

```{r fishnet generation, warning=FALSE, message=FALSE}
fishnet = 
  st_make_grid(chicagoBoundary,
               cellsize = 500, 
               square = TRUE) %>%
  .[chicagoBoundary] %>%            # fast way to select intersecting polygons
  st_sf() %>%
  mutate(uniqueID = 1:n())

crash_net = 
  dplyr::select(crash18) %>% 
  mutate(countCrash = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countCrash = replace_na(countCrash, 0),
         uniqueID = 1:n(),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE))

ggplot() +
  geom_sf(data = crash_net, aes(fill = countCrash), color = NA) +
  scale_fill_viridis() +
  labs(title = "Count of Traffic Crash Incidents with fishnet") +
  mapTheme()
```

## Loading Risk Factors

Like previously mentioned, our risk factors will be focused around bars, pot holes, and broken street lights. Bars are used as a way to represent drunk drivers, possibly showing that people who leave bars are more likely to be drunk, and there is a risk of them driving while impaired. With pot holes and broken street lights, they are combined as one single indicator of poor road conditions, and can increase the likelihood of these dangerous incidents.

```{r load other indicators, warning=FALSE, message=FALSE, results='hide'}
bars = read.csv("https://raw.githubusercontent.com/jijinjc/musa-5080-hw3/refs/heads/main/Assignment%20Data%20Files/bars.csv") %>%
  dplyr::select(ADDRESS, ZIP.CODE, LATITUDE, LONGITUDE, LOCATION) %>%
  na.omit() %>%
  st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs = 4326, agr = "constant")%>%
  st_transform(st_crs(fishnet)) %>%
  distinct() %>%
  mutate(LEGEND = 'Bars')

potholes = read.csv("https://raw.githubusercontent.com/jijinjc/musa-5080-hw3/refs/heads/main/Assignment%20Data%20Files/311_Service_Requests_-_Pot_Holes_Reported_-_Historical_20241016.csv")%>%
  dplyr::select(SERVICE.REQUEST.NUMBER, LATITUDE, LONGITUDE, LOCATION) %>%
  rename(SERVICEID = SERVICE.REQUEST.NUMBER) %>%
  na.omit() %>%
  mutate(LEGEND = 'Potholes')

downlights = read.csv("https://raw.githubusercontent.com/jijinjc/musa-5080-hw3/refs/heads/main/Assignment%20Data%20Files/311_Service_Requests_-_Street_Lights_-_All_Out_-_Historical_20241016.csv") %>%
  dplyr::select(Service.Request.Number, Latitude, Longitude, Location) %>%
  rename(SERVICEID = Service.Request.Number,
         LATITUDE = Latitude,
         LONGITUDE = Longitude,
         LOCATION = Location) %>%
  na.omit() %>%
  mutate(LEGEND = 'Broken_Lights')

hazards = full_join(potholes, downlights, by=names(potholes)) %>%
  st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs = 4326, agr = "constant") %>%
  st_transform(st_crs(fishnet)) %>%
  distinct()

neighborhoods = 
  st_read("https://raw.githubusercontent.com/blackmad/neighborhoods/master/chicago.geojson") %>%
  st_transform(st_crs(fishnet)) 
```

With the risk factors loaded, we will be joining them with our fishnets such that we can better look at how the risk factors affect the traffic crashes that are prevalent in Chicago, and thus identify patterns in a much easier manner.

```{r fishnet for bar and hazards, warning=FALSE, message=FALSE}
bars_net = bars %>%
  st_join(fishnet, join=st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID, LEGEND) %>%
  summarize(count = n()) %>%
  left_join(fishnet, ., by = "uniqueID") %>%
  spread(LEGEND, count, fill=0) %>%
  dplyr::select(-`<NA>`) %>%
  ungroup() 

bars_net = bars_net %>%
  mutate(bars.nn = nn_function(st_coordinates(st_centroid(bars_net)), 
                                           st_coordinates(bars),
                                           k = 5))

hazard_net = hazards %>%
  st_join(fishnet, join=st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID, LEGEND) %>%
  summarize(count = n()) %>%
  left_join(fishnet, ., by = "uniqueID") %>%
  spread(LEGEND, count, fill=0) %>%
  mutate(totHazards = Broken_Lights + Potholes) %>%
  dplyr::select(-`<NA>`) %>%
  ungroup()

hazard_net = hazard_net %>%
  mutate(hazards.nn = nn_function(st_coordinates(st_centroid(hazard_net)), 
                                           st_coordinates(hazards),
                                           k = 1))
```

## Nearest Neighbour Visualization

For each traffic crash location, we calculated the average nearest neighbour distance to the 5 closest bars and the distance to the single closest hazard. By calculating nearest neighbour distances, we can improve the analysis by providing a smoother exposure relationship across space between our risk indicators and traffic crashes. We can see in the visualization that hazards are much more common near the traffic crash locations, whereas the distance between traffic crashes and the average distance to the nearest 5 bars can be close or relatively far.

```{r nearest neighbours, warning=FALSE, message=FALSE}
bars_net.long.nn = 
  dplyr::select(bars_net, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)

hazard_net.long.nn = 
  dplyr::select(hazard_net, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)

grid.arrange(ncol=2,
ggplot() +
      geom_sf(data = bars_net.long.nn, aes(fill=value), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Bars NN Distance") +
      mapTheme(),

ggplot() +
      geom_sf(data = hazard_net.long.nn, aes(fill=value), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Hazards NN Distance") +
      mapTheme()
)
```

## Final Fishnet

For our final feature engineering approach, we look at creating our finalized fishnet by using spatial join to combine the fishnet's centroids to Chicago's neighborhoods and police districts. We also join the crash and the risk feature counts together with the final net, and omit any NA grid cells.

```{r wrangle final net, warning=FALSE, message=FALSE}
final_net =
  left_join(crash_net, st_drop_geometry(bars_net), by="uniqueID") %>%
  left_join(st_drop_geometry(hazard_net), by="uniqueID")

final_net =
  st_centroid(final_net) %>%
  st_join(dplyr::select(neighborhoods, name), by = "uniqueID") %>%
  st_join(dplyr::select(policeDistricts, District), by = "uniqueID") %>%
  st_drop_geometry() %>%
  left_join(dplyr::select(final_net, geometry, uniqueID)) %>%
  st_sf() %>%
  mutate(totHazards = Broken_Lights + Potholes) %>%
  na.omit()
```

# Local Moran's I

To gain a better understanding of the spatial patterns with traffic crashes, we need to use local Moran's I to evaluate whether or not traffic crashes are randomly distributed relative to their immediate neighbors. By using queen contiguity, we create a spatial weights matrix to connect each grid cell with its immediate neighbouring grid cells.

```{r neighbour list and spatial weights matrix, warning=FALSE, message=FALSE}
final_net.nb = poly2nb(as_Spatial(final_net), queen=TRUE)

final_net.weights = nb2listw(final_net.nb, style="W", zero.policy=TRUE)

lm_crash = localmoran(final_net$countCrash, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()


final_net.lm = 
  cbind(lm_crash, as.data.frame(final_net)) %>% 
  st_sf() %>%
  dplyr::select(Crash_count = countCrash, 
                Local_Morans_I = Ii, 
                P_Value = `Pr(z != E(Ii))`) %>%
  mutate(Significant_Hotspots = ifelse(P_Value <= 0.001, 1, 0)) %>%
  gather(Variable, Value, -geometry)
```

After calculating the local Moran’s I and visualizing the results, we can identify various traffic crash hot spots. The “significant hotspots” map on the far right shows that in those regions colored in yellow, crashed are archived more times than other areas not due to randomness (p \<= 0.01). The local Moran's I plot as well as p-value map suggests that, once again, the significant hot spots exist in the loop since the local Moran's I is higher near the loop and the p-value is practically 0 in the same area, and thus the patter is highlighted in the hot spot map, too.

```{r morans i, fig.height=4, fig.width=7, warning=FALSE, message=FALSE}
vars = unique(final_net.lm$Variable)
varlist = list()

for(i in vars){
  varlist[[i]] = 
    ggplot() +
      geom_sf(data = filter(final_net.lm, Variable == i), 
              aes(fill = Value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme(title_size = 8) + 
    theme(plot.title = element_text(hjust = 0.5), 
          plot.margin = margin(5, 5, 5, 5),
          legend.position="bottom")}

do.call(grid.arrange,c(varlist, ncol = 4, top = "Local Morans I statistics for Traffic Crashes"))
```

## Significant Clusters

After looking at the local Moran's I, we shift our focus to creating a dummy variable for significant clusters as well as looking at the average nearest neighbor distance from each final net cell centroid to its nearest significant cluster. This will allows us to model important information in regards to traffic crash's local spatial processes.

```{r significant clusters and nn, warning=FALSE, message=FALSE}
final_net =
  final_net %>% 
  mutate(crash.isSig = 
           ifelse(localmoran(final_net$countCrash, 
                             final_net.weights, zero.policy=TRUE)[,5] <= 0.001, 1, 0)) %>%
  mutate(crash.isSig.dist = 
           nn_function(st_coordinates(st_centroid(final_net)),
                       st_coordinates(st_centroid(
                         filter(final_net, crash.isSig == 1))), 1))
```

# Correlation Plot

We will also be using correlation plots to look at information in regards to features that may have an effect on our traffic crash counts. From our plots below, we can see that counts of all risk factors produced positive correlations, whereas their nearest neighbour distances produced negative correlations. These results show that if therer is an increase in the number of risk factors in close proximity, the higher the likelihood of a traffic crash occurring. Conversely, this would also mean that traffic crashes are less likely to occur.

In fact, the correlation plots show that both the number of bars and the number of hazards proved to have quite a high relationship, possibly indicating that impaired driving and poor road conditions are both factors that we can assume has an impact on traffic crashes.

```{r correlations, fig.height=16, warning=FALSE, message=FALSE, results='hide'}
correlation.long =
  st_drop_geometry(final_net) %>%
  dplyr::select(-uniqueID, -cvID,  -name) %>%
  gather(Variable, Value, -countCrash) %>%
  mutate(Value = as.numeric(Value))

correlation.cor =
  correlation.long %>%
  group_by(Variable) %>%
  summarize(correlation = cor(Value, countCrash, use = "complete.obs"))

ggplot(correlation.long, aes(Value, countCrash)) +
  geom_point(size = 0.1) +
  geom_text(data = correlation.cor, aes(label = paste("r =", round(correlation, 2))),
            x=-Inf, y=Inf, vjust = 1.5, hjust = -.1) +
  geom_smooth(method = "lm", se = FALSE, colour = "black") +
  facet_wrap(~Variable, ncol = 2, scales = "free") +
  labs(title = "Traffic Crash count as a function of risk factors") +
  plotTheme()
```

# Cross-validation

We also need to spatially cross validate our data and findings in order to test our generalizability. To do this, we will be using fields assigning a random `cvID` to each of the grid cells in `final_net` as well as neighbourhood name and police districts as three fields to use in applying a random k-fold cross-validation. 

We will also be using ‘Leave-one-group-out’ cross-validation (LOGO-CV) where we hold-out each neighbourhood, and the model is trained on the remaining *n-1* areas. This way each neighborhood is used as a test case, and we are able to obtain both the observed and predicted traffic crash counts.

```{r cross validation, results='hide', warning=FALSE, message=FALSE, results='hide'}
reg.vars = c("bars.nn", "hazards.nn")

reg.ss.vars = c("bars.nn", "hazards.nn", "crash.isSig", "crash.isSig.dist")

reg.cv = crossValidate(
  dataset = final_net,
  id = "cvID",
  dependentVariable = "countCrash",
  indVariables = reg.vars) %>%
  dplyr::select(cvID = cvID, countCrash, Prediction, geometry)

reg.spatialCV = crossValidate(
  dataset = final_net,
  id = "name",
  dependentVariable = "countCrash",
  indVariables = reg.vars) %>%
  dplyr::select(cvID = name, countCrash, Prediction, geometry)

reg.ss.cv = crossValidate(
  dataset = final_net,
  id = "cvID",
  dependentVariable = "countCrash",
  indVariables = reg.ss.vars) %>%
  dplyr::select(cvID = cvID, countCrash, Prediction, geometry)

reg.ss.spatialCV = crossValidate(
  dataset = final_net,
  id = "name",
  dependentVariable = "countCrash",
  indVariables = reg.ss.vars) %>%
  dplyr::select(cvID = name, countCrash, Prediction, geometry)

reg.summary = 
  rbind(
    mutate(reg.cv,           Error = Prediction - countCrash,
           Regression = "Random k-fold CV: Just Risk Factors"),
    
    mutate(reg.ss.cv,        Error = Prediction - countCrash,
           Regression = "Random k-fold CV: Spatial Process"),
    
    mutate(reg.spatialCV,    Error = Prediction - countCrash,
           Regression = "Spatial LOGO-CV: Just Risk Factors"),
    
    mutate(reg.ss.spatialCV, Error = Prediction - countCrash,
           Regression = "Spatial LOGO-CV: Spatial Process")) %>%
  st_sf() 
```

By using the two cross validation techniques mentioned above, we are able to produce the following results. For the Random k-fold cross validation, we can see that the MAE is generally lower for random k-fold cross validation compared to the same category when using LOGO-CV, therefore the model is relatively more consistent and not variable. Additionally, the cross validation using both risk factors and spatial processes performs more reliably than just the risk factors. This highlights the importance of spatial factors in our analysis, as they can greatly affect our traffic crash counts and the accuracy of these counts. 

On the other hand, with the LOGO-CV method, the MAE compared to the random k-fold cross validation is significantly more spread out and have much higher values, showing that the accuracy of the former method is much lower than that of the latter. This unfortunately suggests that the model is much more variable and less consistent. However, we can still see a similar pattern that the LOGO-CV has that was observed in the random k-fold cv, in which the cross validation that considers spatial process has a lower variation, and thus smaller MAE compared to just considering the risk factors. Once again, this corroborates how important the spatial factors are for our prediction of traffic crash counts. The larger MAE displayed by the LOGO-CV also means that randomly splitting our data does not capture the importance of spatial dependencies well.

```{r mae kfold and logocv, fig.width=12, fig.height=8, warning=FALSE, message=FALSE, results='hide'}
error_by_reg_and_fold = 
  reg.summary %>%
  group_by(Regression, cvID) %>% 
  summarize(Mean_Error = mean(Prediction - countCrash, na.rm = T),
            MAE = mean(abs(Mean_Error), na.rm = T),
            SD_MAE = mean(abs(Mean_Error), na.rm = T)) %>%
  ungroup()

error_by_reg_and_fold %>%
  ggplot(aes(MAE)) + 
  geom_histogram(bins = 30, colour="black", fill = "#FDE725FF") +
  facet_wrap(~Regression) +  
  geom_vline(xintercept = 0) + scale_x_continuous(breaks = seq(0, 8, by = 1)) + 
  labs(title="Distribution of MAE", subtitle = "k-fold cross validation vs. LOGO-CV",
       x="Mean Absolute Error", y="Count") +
  theme(
    axis.text.x = element_blank(), 
  ) +
  plotTheme()
```

# Error Table

In the table below, we are once again shown that spatial process features indeed improve our models, and that the spatial logo-cv has a notably higher mean MAE and standard deviation of MAE. The random k-fold cross validation results show a consistently better results, but the better results could be inflated since the method does not consider spatial correlation, and thus explains why the spatial LOGO-CV's more realistic assessment of the model's performance resulted in a higher MAE. The importance of spatial process is also displayed via the large change between the two mean MAE for both spatial LOGO-CVs, emphasizing the impact that spatial relationship has on analyzing traffic crashes and the importance of considering the factor.

```{r mae table, results='hide', warning=FALSE, message=FALSE}
st_drop_geometry(error_by_reg_and_fold) %>%
  group_by(Regression) %>% 
  summarize(Mean_MAE = round(mean(MAE), 2),
            SD_MAE = round(sd(MAE), 2)) %>%
  kable() %>%
  kable_styling("striped", full_width = F) %>%
  row_spec(2, color = "black", background = "#FDE725FF") %>%
  row_spec(4, color = "black", background = "#FDE725FF") 
```

The map below extends the table, and shows the errors of each regression method. We see that in general the random k-fold cross validation is relatively monotone, showing that errors are evenly dispersed across Chicago, whereas the spatial LOGO-CV maps show higher MAEs near the Loop in Chicgao. 

```{r mae map, fig.width=8, fig.height=5, warning=FALSE, message=FALSE,}
error_by_reg_and_fold %>%
  group_by(Regression) %>%
  ggplot() +
  geom_sf(aes(fill = MAE)) +
  facet_wrap(~Regression, ncol = 4) +  # Arrange all plots in 1 row (4 columns)
  scale_fill_viridis() +
  labs(title = "Error of Crashes via Usage of LOGO-CV Regression") +
  mapTheme(title_size = 10) +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.margin = margin(5, 5, 5, 5),
    legend.position = "bottom",
    strip.text.x = element_text(size = 8)  # Adjust facet title size
  )
```

# Prediction Accuracy

By looking at the figure below, we can generally see that the trend for all four models show that predictions are high for areas with lower traffic crash counts, whereas hot spots with higher traffic crashes tend to be underpredicted. The large difference in predicted and observed values in hotspot areas could likely represent the lack of ability in predicting hotspot areas accurately, whereas the higher prediction over observed values could be a result of overgeneralization.

```{r predicted vs observed crash, results='hide', warning=FALSE, message=FALSE}
st_drop_geometry(reg.summary) %>%
  group_by(Regression) %>%
  mutate(Crash_Decile = ntile(countCrash, 10)) %>%
  group_by(Regression, Crash_Decile) %>%
  summarize(meanObserved = mean(countCrash, na.rm = T),
            meanPrediction = mean(Prediction, na.rm = T)) %>%
  gather(Variable, Value, -Regression, -Crash_Decile) %>%
  ggplot(aes(Crash_Decile, Value, colour = Variable)) +  # Map color to Variable
  geom_point(size = 2) + 
  geom_path(aes(group = Crash_Decile), colour = "black") +
  scale_color_manual(values = c("#006d2c", "#74c476")) +  # Use different colors
  facet_wrap(~Regression) +
  xlim(0, 10) +
  theme(
    plot.title = element_markdown(size = 14, face = "bold", hjust=0.5),
    plot.margin = margin(5, 5, 5, 5),
    strip.text.x = element_text(size = 8),
    legend.position = "none"
  ) +
  labs(title = "<span style = 'color:#74c476;'>Predicted</span> and <span style = 'color:#006d2c;'>Observed</span> Crash by Observed Crash Decile")
```

## Kernel Density Plots

We will be using Kernel Density Estimations (KDE) to model the spatial distribution of traffic crashes and identify areas of high concentration. Additionally, we will be  able to use KDE to visualize the highest density locations and gradually smooths and decreases the probability of traffic crash occurrences as the distance from the point increases. In general, we once again see the pattern of the high density being the Chicago Loop, and there being no other high density locations.

```{r kernel density 2018, warning=FALSE, message=FALSE}
crash.ppp.18 <- as.ppp(st_coordinates(crash18), W = st_bbox(final_net))
crash.kd.18 <- density.ppp(crash.ppp.18, 1000)

as.data.frame(crash.kd.18) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(final_net)) %>%
  aggregate(., final_net, mean) %>%
   ggplot() +
     geom_sf(aes(fill=value)) +
     geom_sf(data = sample_n(crash18, 1500), size = .5) +
     scale_fill_viridis(name = "Density") +
     labs(title = "Kernel density of Traffic Crash in 2018, Chicago") +
     mapTheme()
```

```{r kernel density 2019, warning=FALSE, message=FALSE, include=FALSE}
crash19 = read.csv("https://raw.githubusercontent.com/jijinjc/musa-5080-hw3/refs/heads/main/Assignment%20Data%20Files/Traffic_Crashes_-_2019.csv") %>%
    dplyr::select(CRASH_RECORD_ID, CRASH_DATE, LATITUDE, LONGITUDE, LOCATION) %>%
    na.omit() %>%
    st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs = 4326, agr = "constant")%>%
    st_transform('ESRI:102271') %>%
    distinct()

crash.ppp.19 <- as.ppp(st_coordinates(crash19), W = st_bbox(final_net))
crash.kd.19 <- density.ppp(crash.ppp.19, 1000)

as.data.frame(crash.kd.19) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(final_net)) %>%
  aggregate(., final_net, mean) %>%
   ggplot() +
     geom_sf(aes(fill=value)) +
     geom_sf(data = sample_n(crash19, 1500), size = .5) +
     scale_fill_viridis(name = "Density") +
     labs(title = "Kernel density of Traffic Crash in 2019, Chicago") +
     mapTheme()
```

We then need to check the effectiveness of our model, and thus use a goodness of fit indicator to illustrate whether the risk prediction model is more robust tool by evaluating whether the 2018 kernel density or risk predictions capture more of the 2019 traffic crash incidents. By aligning the 2018 predictions and 2019 observed traffic crash locations, we can visualize whether or not the predictions overlap with the observed data. By using this approach, we are able to determine which method between the KDE or risk-based model is better at predicting traffic crash incidents. 

```{r kernel and risk creation, warning=FALSE, message=FALSE, results='hide'}
crash.kd.sf.19 <- as.data.frame(crash.kd.19) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(final_net)) %>%
  aggregate(., final_net, mean) %>%
  mutate(label = "Kernel Density",
         Risk_Category = ntile(value, 100),
         Risk_Category = case_when(
           Risk_Category >= 90 ~ "90% to 100%",
           Risk_Category >= 70 & Risk_Category <= 89 ~ "70% to 89%",
           Risk_Category >= 50 & Risk_Category <= 69 ~ "50% to 69%",
           Risk_Category >= 30 & Risk_Category <= 49 ~ "30% to 49%",
           Risk_Category >= 1 & Risk_Category <= 29 ~ "1% to 29%")) %>%
  cbind(
    aggregate(
      dplyr::select(crash19) %>% mutate(CrashCount = 1), ., sum) %>%
    mutate(CrashCount = replace_na(CrashCount, 0))) %>%
  dplyr::select(label, Risk_Category, CrashCount)

crash.risk.sf <-
  filter(reg.summary, Regression == "Random k-fold CV: Spatial Process") %>%
  mutate(label = "Risk Predictions",
         Risk_Category = ntile(Prediction, 100),
         Risk_Category = case_when(
           Risk_Category >= 90 ~ "90% to 100%",
           Risk_Category >= 70 & Risk_Category <= 89 ~ "70% to 89%",
           Risk_Category >= 50 & Risk_Category <= 69 ~ "50% to 69%",
           Risk_Category >= 30 & Risk_Category <= 49 ~ "30% to 49%",
           Risk_Category >= 1 & Risk_Category <= 29 ~ "1% to 29%")) %>%
  cbind(
    aggregate(
      dplyr::select(crash19) %>% mutate(CrashCount = 1), ., sum) %>%
      mutate(CrashCount = replace_na(CrashCount, 0))) %>%
  dplyr::select(label,Risk_Category, CrashCount)
```

Based on the resulting graph shown below, we can see that there are some major differences between our model and the kernel density model. While both maps show a cluster of highest risk in the Chicago Loop, the distribution is quite different. Our predictors actually show that there is generally lower risk in the South than that in the Kernel Density, and that higher risks pertain across Northern Chicago. Furthermore, the Kernel Density map shows two other smaller clusters of the highest risk, whereas our risk predictions model show the highest risk locations to be a bit more spread out. The Kernel Density map also shows two clusters in the South that our model does not.

```{r kernel vs risk map, warning=FALSE, message=FALSE, results='hide'}
rbind(crash.kd.sf.19, crash.risk.sf) %>%
  na.omit() %>%
  gather(Variable, Value, -label, -Risk_Category, -geometry) %>%
  ggplot() +
    geom_sf(aes(fill = Risk_Category), colour = NA) +
    geom_sf(data = sample_n(crash19, 3000), size = .5, colour = "black") +
    facet_wrap(~label, ) +
    scale_fill_viridis(discrete = TRUE) +
    labs(title="Comparison of Kernel Density and Risk Predictions",
         subtitle="2018 Traffic Crash Risk Predictions vs 2019 Crashes") +
    mapTheme()
```

Finally, to quantitatively visualize the difference between the Kernel Density and our Risk predictions, we created a bar plot to compare how well the two models model captures traffic crash incidents across different risk categories. We can see that generally our risk prediction is able to outperform Kernel Density for risk areas of less than 50%, and unfortunately underperforms compared to Kernel Density if the risk areas are higher than 50%. This would suggest that our risk prediction models do nnot offer an approach for allocating police resources to high risk locations efficiently.

```{r risk vs kernel bar, warning=FALSE, message=FALSE}
rbind(crash.kd.sf.19, crash.risk.sf) %>%
  st_set_geometry(NULL) %>% na.omit() %>%
  gather(Variable, Value, -label, -Risk_Category) %>%
  group_by(label, Risk_Category) %>%
  summarize(countCrash = sum(Value)) %>%
  ungroup() %>%
  group_by(label) %>%
  mutate(Rate_of_test_set_crash = countCrash / sum(countCrash)) %>%
    ggplot(aes(Risk_Category,Rate_of_test_set_crash)) +
      geom_bar(aes(fill=label), position="dodge", stat="identity") +
      scale_fill_manual(values = c("#756bb1", "#fff200")) + 
      labs(title = "") +
      plotTheme() + 
      theme(axis.text.x = element_text(angle = 45, vjust = 0.5),
      plot.title = element_markdown(size = 14, face = "bold", hjust=0.5),
      plot.margin = margin(5, 5, 5, 5),
      strip.text.x = element_text(size = 8),
      legend.position = "none"
      ) +
      labs(title = "<span style = 'color:#d4ca13;'>Risk Prediction</span> vs. <span style = 'color:#756bb1;'>Kernel Density</span> for 2019 Traffic Crashes")
```

# Conclusion

Through this analysis of predictive models in regards to traffic crash incidents in Chicago, we were able to discover several key findings that could help in enhancing predictive accuracy. More specifically, our analysis indicates the importance of spatial process variables such as proximity to hotspots in the predictive models, as it significantly increases the performance from just using risk factors. However, despite these findings, the model at its current stage should not recommendbe to the local police to deter traffic crash incidents. While the algorithm shows potential in identifying high-risk areas and patterns using geospatial data, there are several concerns that need to be addressed before deployment.

Unfortunately, the accuracy and reliability of the predictions are still uncertain. When pitched against the traditional Kernel Density estimation, our model fell short when predicting the traffic crashes in a future year for many of the higher risk category locations in Chicago. Additionally, the model seemed both over and under estimate traffic crash counts, which would result in highly inefficient allocation of police resources.

Therefore, I would recommend further refinement and testing of the model before considering any practical application by law enforcement agencies. Future analysis can focus on including larger and more diverse datasets to improve accuracy, such as aspects like traffic congestion, or differentiation between vehicle to vehicle crashes and vehicle to pedestrian crashes. By implementing more datasets, it is highly possible that we can increase the accuracy of the model to possibly be implemented in helping control traffic crash incidents.